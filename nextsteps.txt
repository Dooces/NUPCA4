2) Fovea is not being directed properly in the actual run (as evidenced by output.txt + state)
The fatal issue: observation budget is being silently violated

In test4.py, you configure:

B = D (one dim per block),

fovea_blocks_per_step = 32 (budget = 32 “blocks”),

…but the run log shows the actual observation set size is far larger because make_observation_set() expands to a circle:

From output.txt step traces (468 steps total):

obs_count: min 32, max 400, mean 233.7, median 231.5

Fraction of steps:

obs_count > 64: 92.5%

obs_count > 128: 82.3%

obs_count == 400 (full grid): 3.4%

This is not a small deviation; it changes the regime from “foveated partial observation” to “often near-global observation.”

Concrete inconsistency in the saved state (rested.pkl)

At the end of the run, the persistent state shows:

len(state.fovea.current_blocks) = 32

len(state.buffer.observed_dims) = 194

overlap: only 30 dims are both “selected blocks” and “observed dims”

164 observed dims were not in the selected block set

That mismatch is exactly what the circular expansion creates when B = D (each block = one dim). Under strict A16 semantics, observed dims should be the dims of the selected blocks, not an expanded superset.

Second structural issue: test4 runs fovea selection twice per step

You are calling select_fovea() in test4.py to choose indices for the environment, and the agent pipeline also runs its own fovea selection internally (A16.3 planning). That’s why output.txt contains 936 select_fovea events for 468 steps (two per step).

This is not new (zip3 already did it), but it matters because it means the harness is not a clean “agent chooses O_t → env returns y_t on O_t” loop driven by the pipeline’s own planned selection. The pipeline does have an override mechanism (EnvObs.selected_blocks + allow_selected_blocks_override), but test4.py does not populate selected_blocks, so internal planning and external sensing can drift.

3) REST is happening and appears to be doing its intended job (with one major compliance gap)
What’s working (based on output.txt)

REST occurs: 142 / 468 steps were logged with rest: true.

During REST, structural work is performed:

edits_processed: min 16, max 32, mean 16.5 per REST step

rest_queue_len is typically 16, with an early spike up to 152, which then gets worked down (consistent with backlog processing).

Learning is disabled in REST:

learning.active is never true when rest: true in the trace, which matches A10/A14 expectations.

The compliance gap: “REST-purged pixels” is not implemented in the persisted “rested” state

Your axiom file in zip6 (axioms/NUPCA3_axioms_v1.6.2.md) explicitly states (v1.6 intent):

raw observation buffer may be used during REST,

must be purged before leaving REST (“no pixels after REST”),

and feeding raw pixels directly into x(t) is explicitly called out as non-compliant until an encoder boundary exists.

In the saved rested.pkl, state.buffer.x_last and state.buffer.x_prior are present and populated. In this harness, those are effectively raw grid/pixel-coded values. The “drain REST backlog then save rested state” procedure therefore does not produce a “post-REST durable state with no pixels.”

This is an axiomatic noncompliance relative to the v1.6.2 addendum and also contradicts what the save path implies by naming (“rested”).

4) The persistent state is saving too much (content-wise), and the root cause is structural
Observed: rested.pkl is extremely large

rested.pkl in zip6 is ~130 MB.

output.txt is ~419 KB (reasonable).

Why it’s so large (confirmed by inspecting the loaded state)

The dominant contributor is state.observed_transitions:

It stores per-block TransitionRecords.

Each TransitionRecord currently stores observed_dims_tau_plus_1 as a full set of observed dims.

Because B = D and because your actual obs_count is often ~200+, the system records many transitions per step, each duplicating a large observed-dims set.

This creates an O(|O|²) growth pattern in memory footprint per step when the observation set is large.

Even if you fix the circular expansion, this remains inherently heavier than necessary when B = D, but with strict fovea budgets it becomes manageable. With circular expansion, it becomes pathological.

5) Is the agent learning?

Within the constraints of this harness, there is evidence of learning in the logged metrics:

prior_obs_mae drops substantially over the run:

mean over first 50 steps: ~0.895

mean over last 50 steps: ~0.366 (about 59% reduction)

Learning updates are gated and sparse:

learning.active is true on 26 operating steps (and never during REST).

However, because observation is frequently near-global (due to the circle expansion), this is not a clean test of “learning under foveated partial observability,” and it is not a clean test of A16-driven attention either.

Fail (structural/axiomatic issues that materially break the run)

Observation budget violation caused by the new circular expansion in make_observation_set() when grid_side > 0. This breaks the practical meaning of A16 foveation in test4 and cascades into state/log blowups.

“Rested” snapshot is not REST-purged: raw buffer content remains in rested.pkl, contradicting the v1.6.2 “no pixels after REST” addendum (and the file name implies the opposite).

Persistence content is excessive: observed_transitions duplicates large observed-dims sets per block transition; with the expanded observation set this becomes pathological and is the main reason the saved state is ~130 MB.

test4.py should provide a peripheral/full-field gist channel (separate sensor) to the agent