You are right that the hierarchical/mixed-resolution rewrite is a cross-cutting refactor. I would not attempt it “all at once.” The correct path is a staged implementation that (a) preserves the existing `blocks: List[List[int]]` contract as long as possible, and (b) proves value with the smallest number of moving parts before you touch coverage bookkeeping and block-local constraints.

### Preferred approach: staged implementation, with a minimal prototype embedded early

#### Stage 0 — Compatibility scaffolding (no behavior change)

Goal: introduce the new abstractions without changing pipeline semantics.

* Add `BlockSpec` (id, dims, cost, level, parent, children, kind) and a `BlockView`/adapter that can produce:

  * legacy `blocks: List[List[int]]` (leaf-only)
  * `block_cost[id]`
  * `block_kind[id]` (leaf vs coarse vs transport, etc.)
* Keep selector in “legacy mode”: cost=1 for all blocks, select K blocks exactly as today.
* Add unit tests that assert: given a fixed seed and same inputs, the selected block IDs match current behavior.

This de-risks the refactor by ensuring you can land structural changes without destabilizing learning.

#### Stage 1 — Budgeted selection over existing leaf blocks only (small surface area)

Goal: replace “observe K blocks” with “spend budget,” but without hierarchy, aggregation, or new dims.

* Implement budgeted selection as a knapsack-like greedy:

  * sort by `score(b)/cost(b)`
  * add blocks until `Σ cost ≤ budget`
* Define `cost(b)` initially as `len(block_dims)` (or a fixed per-block cost if you want).
* Leave everything else unchanged:

  * coverage stats remain per leaf block
  * residuals computed per observed block as now
  * rest of pipeline still consumes `O_t` built from the selected leaf dims

This isolates one variable: **budgeting**. If this breaks anything, you know it’s the selector, not hierarchy.

#### Stage 2 — Mixed-resolution blocks without hierarchical aggregation (prototype that proves the concept)

Goal: add “cheap large-area signal” without rewriting bookkeeping.

Do **not** implement parent/child residual aggregation yet. Instead, introduce *coarse dims as their own blocks*.

* Append a small set of coarse summary dims to the state vector (call them “peripheral bins” or “pooled occupancy”):

  * Example for your square world: a 2×2 or 4×4 pooled occupancy grid (or low-frequency DCT coefficients).
* Treat each coarse region as its own `BlockSpec(kind="coarse")` with low `cost`.
* Coarse residual and age are computed directly from those coarse dims when observed (no need to aggregate from leaves).
* Selector can now mix:

  * always-on or frequently-on coarse blocks (cheap)
  * a few fine leaf blocks (expensive) where coarse residual is high

This gives you the main behavioral advantage (coarse-to-fine routing) while touching only:

* observation geometry (state includes coarse dims)
* fovea selection (budgeted mixing)
* `O_t` construction

It does **not** require rewriting coverage bookkeeping or block-local node constraints.

#### Stage 3 — Hierarchical constraints and aggregation (only if Stage 2 pays off)

Goal: make the hierarchy “real” (parents summarize children) and enforce clean selection semantics.

* Add “no parent+child simultaneously” selection constraint.
* Implement age/residual propagation (e.g., `res(parent)=max(res(child))`, `age(parent)=min/mean(age(child))`) only after you have stable mixed-resolution behavior.
* Revisit A7.2 coverage semantics if you want “parent coverage implies partial child coverage” (this is a design choice and must be explicit).

#### Stage 4 — Structural edits and block-local constraints (separate decision)

Goal: decide whether constellations remain block-contained in the *leaf sense*, while allowing:

* transport constellations as global operators, and/or
* coarse constellations that live only in coarse dims.

This is where you would touch the enforcement logic, and it should be last.

---

## Why this staging is the correct risk profile

* Stage 1 changes only selection and budgeting; everything downstream remains identical.
* Stage 2 gives you the value proposition (“cheap global signal that can route”) without needing hierarchical bookkeeping correctness.
* Only after you see measurable improvement do you pay the complexity cost of full hierarchy and propagation.

## Minimal prototype I would build first (if you want the quickest proof)

Stage 2, but implemented with the lightest possible coarse features:

* Add coarse pooled occupancy bins for the square world (you already have CLI flags like `--periph-bins` conceptually).
* Make those bins a small number of dims in `x(t)`.
* Make one coarse block per bin (or per group of bins).
* Always include coarse blocks or give them a favorable score/cost so they’re frequently selected.
* Use coarse residual to bias which fine blocks get selected.

If that doesn’t improve “reacquisition” and reduce `mae_pos` in the moving-square run, you’ve learned something decisive: the bottleneck is not routing; it is representational/transport capacity and/or the working-set coverage invariant.

So yes: staged implementation, and the earliest stage should be a minimal mixed-resolution prototype that does not require refactoring the entire block stack.
